{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d1d1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b90e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eecfddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, prediction):\n",
    "    return np.sqrt(np.sum(np.power(true-prediction,2))/len(true))\n",
    "\n",
    "def mean_err(true, prediction):\n",
    "    return np.sum(true-prediction)/len(true)\n",
    "\n",
    "def powerset_no_empty(s):\n",
    "    power_set = []\n",
    "    x = len(s)\n",
    "    for i in range(1 << x):\n",
    "        power_set.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "            \n",
    "    return power_set[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af996b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to the WSB database file\n",
    "conn = sqlite3.connect(\"reddit_wallstreetbets.db\")\n",
    "\n",
    "# create our cursor (this allows us to execute SQL code chunks written as python strings)\n",
    "c = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b054108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_posts now has 6144 entries.\n",
      "post_stats now has 129693 entries.\n"
     ]
    }
   ],
   "source": [
    "#Print out database numbers before ending iteration\n",
    "c.execute(\"SELECT * FROM new_posts\")\n",
    "new_posts_df = pd.DataFrame(c.fetchall(), columns = [x[0] for x in c.description])\n",
    "print( 'new_posts now has '+str(len(new_posts_df))+' entries.' )\n",
    "c.execute(\"SELECT * FROM post_stats\")\n",
    "post_stats_df = pd.DataFrame(c.fetchall(), columns = [x[0] for x in c.description])\n",
    "print( 'post_stats now has '+str(len(post_stats_df))+' entries.' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22b063f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_entries = []\n",
    "upvotes_24hrs = []\n",
    "top_hot_loc = []\n",
    "for i in range(len(new_posts_df)):\n",
    "    c.execute(\"SELECT upvotes FROM post_stats where hour=24 and post_id=\"+str(i))\n",
    "    fetch_val = c.fetchall()\n",
    "    if len( fetch_val ) < 1:\n",
    "        incomplete_entries.append(i)\n",
    "    else:\n",
    "        upvotes_24hrs.append( fetch_val[0][0] )\n",
    "    c.execute(\"SELECT hot_val FROM post_stats where post_id=\"+str(i))\n",
    "    top_hot_loc.append( min(c.fetchall())[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2cce3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vals = []\n",
    "days = []\n",
    "for i in range(len(new_posts_df)):\n",
    "    time_str = new_posts_df[\"submit_time\"][i].split('T')[1]\n",
    "    time_val = float(time_str.split(':')[0])+float(time_str.split(':')[1])/60.+float(time_str.split(':')[2])/360.\n",
    "    time_vals.append(time_val)\n",
    "    day_str = pd.Timestamp( new_posts_df[\"submit_time\"][i].split('T')[0].replace('\"','') ).day_name()\n",
    "    day_str = day_str.replace('Monday','Weekday').replace('Tuesday','Weekday').replace('Wednesday','Weekday').replace('Thursday','Weekday').replace('Friday','Weekday')\n",
    "    day_str = day_str.replace('Saturday','Weekend').replace('Sunday','Weekend')\n",
    "    if day_str == 'Weekend':\n",
    "        days.append( 1 )\n",
    "    else:\n",
    "        days.append( 0 )\n",
    "\n",
    "new_posts_df['submit_hour'] = time_vals\n",
    "new_posts_df['submit_day'] = days\n",
    "new_posts_df['best_hot_val'] = top_hot_loc\n",
    "\n",
    "WSB_df = new_posts_df.drop(incomplete_entries)\n",
    "WSB_df['upvotes_tot'] = upvotes_24hrs\n",
    "\n",
    "#Need a definition of 'viral'\n",
    "#Let's go with more than 2,500 upvotes or making it to the top 5 of the page\n",
    "viral = []\n",
    "for post_id in WSB_df['post_id']:\n",
    "    if (WSB_df['upvotes_tot'][post_id] >= 2500):\n",
    "        viral.append(1)\n",
    "    elif (WSB_df['best_hot_val'][post_id] <= 5):\n",
    "        viral.append(1)\n",
    "    else:\n",
    "        viral.append(0)\n",
    "\n",
    "WSB_df['viral'] = viral\n",
    "\n",
    "#Let's ignore daily discussion threads, since they are at the top of the page but not really viral\n",
    "WSB_df = WSB_df.drop(WSB_df[WSB_df['flair']=='Daily Discussion'].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec295eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one-hot encoded flair variables and add them to the df\n",
    "WSB_df = pd.concat([WSB_df, pd.get_dummies(WSB_df['flair'])], axis=1)\n",
    "\n",
    "#WSB_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e278f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a train/test split\n",
    "WSB_df_train, WSB_df_test = train_test_split(WSB_df, shuffle=True, random_state=48, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1270113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_id', 'active_track', 'title', 'comment_url', 'link_url', 'flair',\n",
       "       'submit_time', 'rising_val', 'hot_val', 'username', 'post_karma',\n",
       "       'comment_karma', 'redditor_for', 'upvotes', 'upvote_percent',\n",
       "       'num_comments', 'submit_hour', 'weekend', 'best_hot_val', 'upvotes_tot',\n",
       "       'viral', 'DD', 'Discussion', 'Earnings Thread', 'Gain', 'Loss', 'Meme',\n",
       "       'Mods', 'News', 'None', 'Shitpost', 'Technical Analysis',\n",
       "       'Weekend Discussion', 'YOLO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSB_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c0cf991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redditor_for          0.001973\n",
      "Shitpost              0.003315\n",
      "Mods                  0.003956\n",
      "None                  0.004103\n",
      "Weekend Discussion    0.004284\n",
      "submit_hour           0.008633\n",
      "comment_karma         0.012438\n",
      "Loss                  0.018050\n",
      "Technical Analysis    0.028796\n",
      "rising_val            0.030917\n",
      "weekend               0.031290\n",
      "Discussion            0.033779\n",
      "Gain                  0.042966\n",
      "DD                    0.046732\n",
      "News                  0.053647\n",
      "YOLO                  0.059538\n",
      "num_comments          0.083288\n",
      "post_karma            0.085229\n",
      "hot_val               0.094973\n",
      "upvote_percent        0.115478\n",
      "Meme                  0.201988\n",
      "upvotes               0.447311\n",
      "upvotes_tot           1.000000\n",
      "Earnings Thread            NaN\n",
      "Name: upvotes_tot, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print( np.abs(WSB_df_train[['rising_val', 'hot_val', 'post_karma',\n",
    "       'comment_karma', 'redditor_for', 'upvotes', 'upvote_percent',\n",
    "       'num_comments', 'submit_hour', 'weekend','DD', 'Discussion',\n",
    "       'Earnings Thread', 'Gain', 'Loss', 'Meme', 'Mods', 'News', 'None',\n",
    "       'Shitpost', 'Technical Analysis', 'Weekend Discussion', 'YOLO',\n",
    "       'upvotes_tot']].corr()['upvotes_tot']).sort_values() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5cce0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262143\n"
     ]
    }
   ],
   "source": [
    "#predictors = powerset_no_empty(['rising_val', 'hot_val', 'post_karma',\n",
    "#       'comment_karma', 'redditor_for', 'upvotes', 'upvote_percent',\n",
    "#       'num_comments', 'submit_hour', 'weekend','DD', 'Daily Discussion', 'Discussion',\n",
    "#       'Earnings Thread', 'Gain', 'Loss', 'Meme', 'Mods', 'News', 'None',\n",
    "#       'Shitpost', 'Technical Analysis', 'Weekend Discussion', 'YOLO'])\n",
    "\n",
    "predictors = powerset_no_empty(['rising_val', 'hot_val', 'post_karma',\n",
    "       'comment_karma', 'redditor_for', 'upvotes', 'upvote_percent',\n",
    "       'num_comments', 'submit_hour', 'weekend','DD', 'Discussion',\n",
    "       'Gain', 'Loss', 'Meme', 'News',\n",
    "       'Technical Analysis', 'YOLO'])\n",
    "\n",
    "#predictors = powerset_no_empty(['rising_val', 'hot_val', 'post_karma',\n",
    "#       'upvotes', 'upvote_percent',\n",
    "#       'num_comments'])\n",
    "\n",
    "print(len(predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93104815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do some k-fold cross-validation\n",
    "n_k = 4\n",
    "#kf = KFold(n_k)\n",
    "kf = StratifiedKFold(n_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e28f4d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% done with k-fold iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rising_val',\n",
       " 'hot_val',\n",
       " 'post_karma',\n",
       " 'comment_karma',\n",
       " 'upvotes',\n",
       " 'upvote_percent',\n",
       " 'weekend',\n",
       " 'Discussion']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I run a cross validation to select best model\n",
    "RMSEs = np.empty((n_k,len(predictors)))\n",
    "reg = LinearRegression(copy_X = True)\n",
    "out_int = 0.0\n",
    "out_per = 0.0\n",
    "def k_fold_loop(i):\n",
    "    global out_int, out_per\n",
    "    train_index = list(kf.split(WSB_df_train,WSB_df_train['upvotes_tot']))[i][0]\n",
    "    test_index = list(kf.split(WSB_df_train,WSB_df_train['upvotes_tot']))[i][1]\n",
    "    # Get the cv train test split\n",
    "    df_train_train = WSB_df_train.iloc[train_index]\n",
    "    df_holdout = WSB_df_train.iloc[test_index]\n",
    "    # For each possible model\n",
    "    for j in range(len(predictors)):\n",
    "        percent = round(100.0*out_int/(n_k*len(predictors)),2)\n",
    "        if percent > out_per+0.05:\n",
    "            clear_output()\n",
    "            print(str(percent)+'% done with k-fold iterations.')\n",
    "            out_per += 0.05\n",
    "        # Cloning the regression makes a fresh regression \n",
    "        # model for each run\n",
    "        clone_reg = clone(reg)\n",
    "        # fit the model\n",
    "        clone_reg.fit(df_train_train[predictors[j]], df_train_train['upvotes_tot'])\n",
    "        pred = clone_reg.predict(df_holdout[predictors[j]])\n",
    "        RMSEs[i,j] = rmse(df_holdout['upvotes_tot'], pred)\n",
    "        out_int += 1.0\n",
    "\n",
    "print(str(0.00)+'% done with k-fold iterations.')\n",
    "for i in range(n_k):\n",
    "    k_fold_loop(i)\n",
    "        \n",
    "best_preds = predictors[np.argmin(np.mean(RMSEs, axis = 0))]\n",
    "best_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b88eda8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Stats\n",
      "Linear regression RMS: 3455.2733788107853\n",
      "Assuming mean RMS: 2908185.1555443085\n",
      "Assuming median RMS: 134167.31713750726\n",
      "\n",
      "Test Set Stats\n",
      "Linear regression RMS: 2658.6506958787077\n",
      "Assuming mean RMS: 605851.1715975517\n",
      "Assuming median RMS: 34241.9194018322\n"
     ]
    }
   ],
   "source": [
    "## Fit linear regression for total upvotes\n",
    "reg = LinearRegression(copy_X=True)\n",
    "reg.fit(WSB_df_train[best_preds],\n",
    "        WSB_df_train['upvotes_tot'])\n",
    "\n",
    "pred = reg.predict(WSB_df_train[best_preds])\n",
    "true = WSB_df_train['upvotes_tot']\n",
    "\n",
    "print(\"Training Set Stats\")\n",
    "print(\"Linear regression RMS:\",rmse(true,pred))\n",
    "print(\"Assuming mean RMS:\",rmse(true,len(true)*np.mean(true)))\n",
    "print(\"Assuming median RMS:\",rmse(true,len(true)*np.median(true)))\n",
    "\n",
    "print()\n",
    "\n",
    "pred = reg.predict(WSB_df_test[best_preds])\n",
    "true = WSB_df_test['upvotes_tot']\n",
    "\n",
    "print(\"Test Set Stats\")\n",
    "print(\"Linear regression RMS:\",rmse(true,pred))\n",
    "print(\"Assuming mean RMS:\",rmse(true,len(true)*np.mean(true)))\n",
    "print(\"Assuming median RMS:\",rmse(true,len(true)*np.median(true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafe1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
