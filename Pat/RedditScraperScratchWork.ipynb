{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96bf967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from urllib.request import Request,urlopen\n",
    "import re\n",
    "\n",
    "header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \n",
    "          'AppleWebKit/537.11 (KHTML, like Gecko) '\n",
    "          'Chrome/23.0.1271.64 Safari/537.11',\n",
    "          'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "          'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "          'Accept-Encoding': 'none',\n",
    "          'Accept-Language': 'en-US,en;q=0.8',\n",
    "          'Connection': 'keep-alive'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fb1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to the WSB database file\n",
    "conn = sqlite3.connect(\"reddit_wallstreetbets.db\")\n",
    "\n",
    "# create our cursor (this allows us to execute SQL code chunks written as python strings)\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1a99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='new_posts'\")\n",
    "if len(c.fetchall()) == 0:\n",
    "    #Using this if statement to make sure this only runs if the table doesn't exist already\n",
    "    #create a table for new posts\n",
    "    c.execute(\"\"\"CREATE TABLE new_posts(\n",
    "                        post_id int,\n",
    "                        active_track text,\n",
    "                        title text,\n",
    "                        comment_url text,\n",
    "                        link_url text,\n",
    "                        flair text,\n",
    "                        submit_time text,\n",
    "                        rising_val int,\n",
    "                        hot_val int,\n",
    "                        username text,\n",
    "                        post_karma int,\n",
    "                        comment_karma int,\n",
    "                        redditor_for int,\n",
    "                        upvotes int,\n",
    "                        upvote_percent int,\n",
    "                        num_comments int,\n",
    "                        PRIMARY KEY (post_id)\n",
    "                    )\"\"\")\n",
    "    # commit this new table to the database\n",
    "    conn.commit()\n",
    "\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='post_stats'\")\n",
    "if len(c.fetchall()) == 0:\n",
    "    #Using this if statement to make sure this only runs if the table doesn't exist already\n",
    "    #create a table for hourly post statistics\n",
    "    c.execute(\"\"\"CREATE TABLE post_stats(\n",
    "                        stat_id int,\n",
    "                        post_id int,\n",
    "                        comment_url text,\n",
    "                        hour int,\n",
    "                        rising_val int,\n",
    "                        hot_val int,\n",
    "                        upvotes int,\n",
    "                        upvote_percent int,\n",
    "                        num_comments int,\n",
    "                        PRIMARY KEY (stat_id)\n",
    "                    )\"\"\")\n",
    "    # commit this new table to the database\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e1d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def check_iterator():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01df306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the newest posts to see if they need to be added\n",
    "newpage_req = Request(url='https://old.reddit.com/r/wallstreetbets/new/',headers=header)\n",
    "newpage_sourceCode = urlopen(newpage_req).read().decode()\n",
    "newpage_urls = re.findall('<li class=\"first\"><a href=\"(.*?)\" data-event-action=\"comments\"', newpage_sourceCode)\n",
    "post_times = re.findall('class=\"live-timestamp\">(.*?)</time>', newpage_sourceCode)\n",
    "\n",
    "\n",
    "#Get the rising page, since we'll need it later as well\n",
    "rising_req = Request(url='https://old.reddit.com/r/wallstreetbets/rising/',headers=header)\n",
    "rising_sourceCode = urlopen(rising_req).read().decode()\n",
    "rising_urls = re.findall('<li class=\"first\"><a href=\"(.*?)\" data-event-action=\"comments\"', rising_sourceCode)\n",
    "\n",
    "\n",
    "#Scrape the first 4 hot pages (so the current top 100 posts + stickied posts)\n",
    "hot1_req = Request(url='https://old.reddit.com/r/wallstreetbets/',headers=header)\n",
    "hot1_sourceCode = urlopen(hot1_req).read().decode()\n",
    "\n",
    "hot2_url = re.findall('<span class=\"next-button\"><a href=\"(.*?)\"', hot1_sourceCode)[0]\n",
    "hot2_req = Request(url=hot2_url,headers=header)\n",
    "hot2_sourceCode = urlopen(hot2_req).read().decode()\n",
    "\n",
    "hot3_url = re.findall('<span class=\"next-button\"><a href=\"(.*?)\"', hot2_sourceCode)[0]\n",
    "hot3_req = Request(url=hot3_url,headers=header)\n",
    "hot3_sourceCode = urlopen(hot3_req).read().decode()\n",
    "\n",
    "hot4_url = re.findall('<span class=\"next-button\"><a href=\"(.*?)\"', hot3_sourceCode)[0]\n",
    "hot4_req = Request(url=hot4_url,headers=header)\n",
    "hot4_sourceCode = urlopen(hot4_req).read().decode()\n",
    "\n",
    "hot_urls = re.findall('<li class=\"first\"><a href=\"(.*?)\" data-event-action=\"comments\"',\n",
    "           hot1_sourceCode+hot2_sourceCode+hot3_sourceCode+hot4_sourceCode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e2dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_post_entry(url_str):\n",
    "    req = Request(url=url_str,headers=header)\n",
    "    sourceCode = urlopen(req).read().decode()\n",
    "    time.sleep(1)\n",
    "\n",
    "    deleted_post = False\n",
    "    if ('<em>[removed]</em>' in sourceCode) or ('<span>[deleted]</span>' in sourceCode):\n",
    "        deleted_post = True\n",
    "        #No need to keep tracking deleted posts\n",
    "        c.execute(\"UPDATE new_posts SET active_track = 'No' where comment_url = '\"+url_str+\"'\")\n",
    "        conn.commit()\n",
    "\n",
    "    if (not '<span class=\"promoted-tag\">' in sourceCode) and (not '?promoted=1' in url_str) and deleted_post==False:\n",
    "        #this skips promoted and deleted posts\n",
    "        active_track = 'Yes'\n",
    "        title = re.findall('property=\"og:title\" content=\"(.*?)\">',sourceCode)[0].replace(\"'\",\"\")\n",
    "        comment_url = url_str\n",
    "        if 'self.wallstreetbets' in sourceCode:\n",
    "            link_url = comment_url\n",
    "            # ^this deals with self-posts\n",
    "        else:\n",
    "            link_url = re.findall('\"target_url\": \"(.*?)\",',sourceCode)[0]\n",
    "        if 'linkflairlabel' in sourceCode:\n",
    "            flair = re.findall('<span class=\"linkflairlabel \" title=\"(.*?)\">',sourceCode)[0]\n",
    "        else:\n",
    "            flair = 'None'\n",
    "        submit_time = re.findall('<span>this post was submitted on &#32;</span><time datetime=(.*?)\">',sourceCode)[0].replace('+00:00','')\n",
    "        if comment_url in rising_urls:\n",
    "            rising_val = rising_urls.index(comment_url)\n",
    "        else:\n",
    "            rising_val = 99\n",
    "        if comment_url in hot_urls:\n",
    "            hot_val = hot_urls.index(comment_url)\n",
    "        else:\n",
    "            hot_val = 999\n",
    "\n",
    "        if 'Posted in r/wallstreetbets' in sourceCode:\n",
    "            username = re.findall('property=\"og:description\" content=\"Posted in r/wallstreetbets by u/(.*?) ',sourceCode)[0]\n",
    "        else:\n",
    "            username = re.findall('<a href=\"https://old.reddit.com/user/(.*?)\" class',sourceCode)[0]\n",
    "            # ^this deals with self-posts\n",
    "        usr_req = Request(url='https://www.reddit.com/user/'+username+'/about.json',headers=header)\n",
    "        usr_sourceCode = urlopen(usr_req).read().decode()\n",
    "        time.sleep(1)\n",
    "\n",
    "        post_karma = re.findall('\"link_karma\": (.*?),',usr_sourceCode)[0]\n",
    "        comment_karma = re.findall('\"comment_karma\": (.*?),',usr_sourceCode)[0]\n",
    "        creation_date = re.findall('\"created_utc\": (.*?),',usr_sourceCode)[0]\n",
    "        redditor_for =  (float(time.time()) - float(creation_date)) / 86400.0 #days\n",
    "\n",
    "        upvotes = re.findall('<div class=\"score\"><span class=\"number\">(.*?)</span>', sourceCode)[0]\n",
    "        upvote_percent = re.findall('span>&#32;\\((.*?)% upvoted', sourceCode)[0]\n",
    "        if '<span class=\"title\">no comments (yet)</span>' in sourceCode:\n",
    "            num_comments = 0\n",
    "        else:\n",
    "            num_comments = re.findall('class=\"bylink comments may-blank\" rel=\"nofollow\" >(.*?) comment', sourceCode)[0]\n",
    "\n",
    "\n",
    "        val_str = str(post_id)+\",'\"+active_track+\"','\"+title+\"','\"+comment_url+\"','\"\n",
    "        val_str+= link_url+\"','\"+flair+\"','\"+submit_time+\"',\"+str(rising_val)+\",\"+str(hot_val)+\",'\"+username+\"',\"\n",
    "        val_str+= str(post_karma).replace(\",\",\"\")+\",\"+str(comment_karma).replace(\",\",\"\")+\",\"+str(redditor_for)+\",\"\n",
    "        val_str+= str(upvotes)+\",\"+str(upvote_percent)+\",\"+str(num_comments)\n",
    "        #print(val_str)\n",
    "        c.execute(\"INSERT INTO new_posts VALUES (\"+val_str+\")\")\n",
    "        conn.commit()\n",
    "\n",
    "        hours_old = 0\n",
    "        val_str = str(stat_id)+\",\"+str(post_id)+\",'\"+url_str+\"',\"+str(hours_old)+\",\"\n",
    "        val_str+= str(rising_val)+\",\"+str(hot_val)+\",\"+str(upvotes)+\",\"+str(upvote_percent)+\",\"+str(num_comments)\n",
    "        #print(val_str)\n",
    "        c.execute(\"INSERT INTO post_stats VALUES (\"+val_str+\")\")\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b639f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_post_monitor(url_str):\n",
    "    c.execute(\"SELECT post_id FROM new_posts WHERE comment_url='\"+url_str+\"'\")\n",
    "    post_id = list(c.fetchall())[0][0]\n",
    "    req = Request(url=url_str,headers=header)\n",
    "    sourceCode = urlopen(req).read().decode()\n",
    "    time.sleep(1)\n",
    "\n",
    "    deleted_post = False\n",
    "    if ('<em>[removed]</em>' in sourceCode) or ('<span>[deleted]</span>' in sourceCode):\n",
    "        deleted_post = True\n",
    "        #No need to keep tracking deleted posts\n",
    "        print(\"Stopping updates for \"+url_str+\"since it's been deleted/removeed.\")\n",
    "        c.execute(\"UPDATE new_posts SET active_track = 'No' where comment_url = '\"+url_str+\"'\")\n",
    "        conn.commit()\n",
    "\n",
    "    if (not '<span class=\"promoted-tag\">' in sourceCode) and (not '?promoted=1' in url_str) and deleted_post==False:\n",
    "        #this skips promoted and deleted posts\n",
    "        upvotes = re.findall('<div class=\"score\"><span class=\"number\">(.*?)</span>', sourceCode)[0]\n",
    "        upvote_percent = re.findall('span>&#32;\\((.*?)% upvoted', sourceCode)[0]\n",
    "        if url_str in rising_urls:\n",
    "            rising_val = rising_urls.index(url_str)\n",
    "        else:\n",
    "            rising_val = 99\n",
    "        if comment_url in hot_urls:\n",
    "            hot_val = hot_urls.index(comment_url)\n",
    "        else:\n",
    "            hot_val = 999\n",
    "        if '<span class=\"title\">no comments (yet)</span>' in sourceCode:\n",
    "            num_comments = 0\n",
    "        else:\n",
    "            num_comments = re.findall('class=\"bylink comments may-blank\" rel=\"nofollow\" >(.*?) comment', sourceCode)[0]\n",
    "        post_age = re.findall('class=\"live-timestamp\">(.*?)</time>', sourceCode)[0]\n",
    "        if 'minutes' in post_age:\n",
    "            hours_old = 0\n",
    "        elif 'day' in post_age:\n",
    "            hours_old = 24\n",
    "            #for simplicity we'll stop tracking posts after they've been up a full day\n",
    "            c.execute(\"UPDATE new_posts SET active_track = 'No' where comment_url = '\"+url_str+\"'\")\n",
    "            conn.commit()\n",
    "        elif 'hour ago' in post_age:\n",
    "            hours_old = 1\n",
    "        else:\n",
    "            hours_old = int(post_age.replace(' hours ago',''))\n",
    "        \n",
    "        c.execute(\"SELECT * FROM post_stats WHERE (comment_url='\"+url_str+\"' and hour=\"+str(hours_old)+\")\")\n",
    "        if len(c.fetchall()) == 0: #Only add a new entry if that hour hasn't yet been recorded for the post in question\n",
    "            print('Updating post data in db for '+url_str)\n",
    "            val_str = str(stat_id)+\",\"+str(post_id)+\",'\"+url_str+\"',\"+str(hours_old)+\",\"\n",
    "            val_str+= str(rising_val)+\",\"+str(hot_val)+\",\"+str(upvotes)+\",\"+str(upvote_percent)+\",\"+str(num_comments)\n",
    "            #print(val_str)\n",
    "            c.execute(\"INSERT INTO post_stats VALUES (\"+val_str+\")\")\n",
    "            conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcbcd7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if posts already in db need to be updated.\n",
      "Checking if new posts need to be added to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc3hsw/wishy_wish/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc3dwu/china_evergrande_ends_talks_on_hopson_deal_asks/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc3de5/impact_of_federal_legalization_on_tlry/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc3bha/i_have_a_feeling_its_about_to_be_a_good_day_boys/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc349l/citadel_has_changed_its_bussiness_profile_due_to/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc30zw/novavax_nvax_is_being_investigated_after_big/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc2uxo/i_suggested_this_few_weeks_ago_and_i_was/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc2u30/china_real_estate_kaisa_bonds_fall_after_investor/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc2sot/undervalued_miner_chart_updated_cifr_hut_mara/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc2s6q/just_wanted_to_check_in_with_my_wish_haters_today/ to db.\n",
      "Adding https://old.reddit.com/r/wallstreetbets/comments/qc2ltl/long_electronic_arts_ea/ to db.\n"
     ]
    }
   ],
   "source": [
    "# Pull database info into a pair of lists\n",
    "c.execute(\"SELECT comment_url FROM new_posts\")\n",
    "db_comment_urls = list( pd.DataFrame(c.fetchall(), columns = [x[0] for x in c.description])[\"comment_url\"] )\n",
    "c.execute(\"SELECT active_track FROM new_posts\")\n",
    "db_active_tracks = list( pd.DataFrame(c.fetchall(), columns = [x[0] for x in c.description])[\"active_track\"] )\n",
    "\n",
    "# Check posts previously in the database\n",
    "print('Checking if posts already in db need to be updated.')\n",
    "for i in range(len(db_comment_urls)):\n",
    "    if db_active_tracks[i] == \"Yes\":\n",
    "        #print('Updating post data in db for '+db_comment_urls[i])\n",
    "        c.execute(\"SELECT * FROM post_stats\")\n",
    "        stat_id = len(c.fetchall())\n",
    "        old_post_monitor(db_comment_urls[i])\n",
    "\n",
    "# Check posts submitted in the last hour\n",
    "print('Checking if new posts need to be added to db.')\n",
    "for i in range(len(post_times)):\n",
    "    if 'minutes' in post_times[i]:\n",
    "        if not newpage_urls[i] in db_comment_urls:\n",
    "            c.execute(\"SELECT * FROM new_posts\")\n",
    "            post_id = len(c.fetchall())\n",
    "            c.execute(\"SELECT * FROM post_stats\")\n",
    "            stat_id = len(c.fetchall())\n",
    "            print('Adding '+newpage_urls[i]+' to db.')\n",
    "            new_post_entry(newpage_urls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9028829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_posts now has 11 entries.\n",
      "post_stats now has 11 entries.\n"
     ]
    }
   ],
   "source": [
    "#Print out database numbers before ending iteration\n",
    "c.execute(\"SELECT * FROM new_posts\")\n",
    "print( 'new_posts now has '+str(len(pd.DataFrame(c.fetchall(), columns = [x[0] for x in c.description])))+' entries.' )\n",
    "c.execute(\"SELECT * FROM post_stats\")\n",
    "print( 'post_stats now has '+str(len(pd.DataFrame(c.fetchall(), columns = [x[0] for x in c.description])))+' entries.' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592328e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
